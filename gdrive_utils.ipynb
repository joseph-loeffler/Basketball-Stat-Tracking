{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkPnAK7xUkciSFQr9c4+pM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joseph-loeffler/Basketball-Stat-Tracking/blob/main/gdrive_utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "D-vwGUq3kqJC"
      },
      "outputs": [],
      "source": [
        "%%capture captured\n",
        "# Library imports\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from googleapiclient.discovery import build\n",
        "from nbconvert import ScriptExporter\n",
        "from google.colab import userdata\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "from functools import wraps\n",
        "import pandas as pd\n",
        "import importlib\n",
        "import nbformat\n",
        "import gspread\n",
        "import shutil\n",
        "import random\n",
        "import time\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Import custom modules (needs a function b/c of Colab limitations)\n",
        "GIT_TOKEN = userdata.get('GIT_TOKEN')\n",
        "def setup_repository(token, repo_url, module_name):\n",
        "    \"\"\"\n",
        "    Clone a GitHub repository, convert a Jupyter notebook to a Python script,\n",
        "    and import the script as a module.\n",
        "\n",
        "    Parameters:\n",
        "        token (str): GitHub personal access token.\n",
        "        repo_url (str): URL of the GitHub repository.\n",
        "        module_name (str): Name of the module to be imported from the repository.\n",
        "    \"\"\"\n",
        "    # Remove existing repository if it exists\n",
        "    repo_name = repo_url.split('/')[-1].replace('.git', '')\n",
        "    repo_path = f'./{repo_name}'\n",
        "    if os.path.exists(repo_path):\n",
        "        shutil.rmtree(repo_path)\n",
        "\n",
        "    repo_url = f\"https://{GIT_TOKEN}:x-oauth-basic@{repo_url.split('//')[-1]}\"\n",
        "    os.system(f'git clone {repo_url}')\n",
        "\n",
        "    def convert_notebook_to_script(nb_path, py_path):\n",
        "        \"\"\"\n",
        "        Convert a Jupyter notebook to a Python script.\n",
        "\n",
        "        Parameters:\n",
        "            nb_path (str): Path to the Jupyter notebook.\n",
        "            py_path (str): Path where the Python script will be saved.\n",
        "        \"\"\"\n",
        "        with open(nb_path, 'r') as f:\n",
        "            nb = nbformat.read(f, as_version=4)\n",
        "        exporter = ScriptExporter()\n",
        "        source, meta = exporter.from_notebook_node(nb)\n",
        "        with open(py_path, 'w') as f:\n",
        "            f.write(source)\n",
        "\n",
        "    repo_name = repo_url.split('/')[-1].replace('.git', '')\n",
        "    repo_path = f'./{repo_name}'\n",
        "    nb_path = os.path.join(repo_path, f'{module_name}.ipynb')\n",
        "    py_path = os.path.join(repo_path, f'{module_name}.py')\n",
        "    convert_notebook_to_script(nb_path, py_path)\n",
        "\n",
        "    sys.path.insert(0, repo_path)  # Add the repository path to sys.path\n",
        "    module = __import__(module_name)\n",
        "\n",
        "    # Reload the module to ensure the latest version is used\n",
        "    importlib.reload(module)\n",
        "\n",
        "    return module\n",
        "\n",
        "# Import globals module w/ constant values\n",
        "globals = setup_repository(\n",
        "    GIT_TOKEN,\n",
        "    'https://github.com/Glencrest-Group/property-billbacks.git',\n",
        "    'globals')\n",
        "import globals as gb\n",
        "\n",
        "\n",
        "# Authenticate user and build Drive service\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "drive_service = build('drive', 'v3', credentials=creds)\n",
        "\n",
        "\n",
        "# General Google Drive API functions to load spreadsheets as dataframes,\n",
        "# move files, get files info from folder, etc.\n",
        "def retry_on_quota_exceeded():\n",
        "    \"\"\"\n",
        "    Decorator that retries the decorated function using an exponential backoff\n",
        "    strategy when a Google Drive or gspread API quota exceeded error (HTTP 429)\n",
        "    occurs. The function will be retried up to `gb.MAX_API_RETRIES` times, with\n",
        "    increasing sleep intervals between retries.\n",
        "\n",
        "    Returns:\n",
        "        function: The decorated function with retry logic applied.\n",
        "\n",
        "    Raises:\n",
        "        Exception: If the maximum number of retries (`gb.MAX_API_RETRIES`) is\n",
        "            exceeded without a successful function execution.\n",
        "    \"\"\"\n",
        "    def decorator_retry(func):\n",
        "        @wraps(func)\n",
        "        def wrapper_retry(*args, **kwargs):\n",
        "            retry_count = 0\n",
        "            while retry_count < gb.MAX_API_RETRIES:\n",
        "                try:\n",
        "                    return func(*args, **kwargs)\n",
        "                except gspread.exceptions.APIError as e:\n",
        "                    error = e.response.json()\n",
        "                    if error['error']['code'] == 429:\n",
        "                        # Handle quota exceeded error with exponential backoff\n",
        "                        retry_count += 1\n",
        "                        sleep_time = (2 ** retry_count) + (random.uniform(0, 1))\n",
        "                        print(f\"API quota exceeded, retrying in {sleep_time:.2f} seconds...\")\n",
        "                        time.sleep(sleep_time)\n",
        "                    else:\n",
        "                        raise  # Re-raise the exception if it's not a quota exceeded error\n",
        "            raise Exception(\"Max retries exceeded. Could not complete the request.\")\n",
        "        return wrapper_retry\n",
        "    return decorator_retry\n",
        "\n",
        "\n",
        "def extract_drive_id(url):\n",
        "    \"\"\"\n",
        "    Extract the file ID from different formats of Google Drive URLs, including\n",
        "    folder, file, and spreadsheet URLs.\n",
        "\n",
        "    Parameters:\n",
        "        url (str): The Google Drive URL from which to extract the file ID.\n",
        "\n",
        "    Returns:\n",
        "        str: The extracted GDrive file ID, or None if no ID could be found.\n",
        "    \"\"\"\n",
        "    # Define a regular expression pattern to match the ID in various types of Google Drive URLs\n",
        "    pattern = r'(?:drive/(?:folders|file|d)/|docs/(?:spreadsheets/d/))([a-zA-Z0-9-_]+)'\n",
        "    match = re.search(pattern, url)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        # Another attempt to match \"spreadsheets\" and \"file\" type URLs specifically\n",
        "        pattern_spreadsheets = r'/spreadsheets/d/([a-zA-Z0-9-_]+)'\n",
        "        match_spreadsheets = re.search(pattern_spreadsheets, url)\n",
        "        if match_spreadsheets:\n",
        "            return match_spreadsheets.group(1)\n",
        "\n",
        "        pattern_file = r'/file/d/([a-zA-Z0-9-_]+)'\n",
        "        match_file = re.search(pattern_file, url)\n",
        "        if match_file:\n",
        "            return match_file.group(1)\n",
        "\n",
        "        return None\n",
        "\n",
        "\n",
        "@retry_on_quota_exceeded()\n",
        "def open_sheet_from_url(spread_url, sheet_index=0, sheet_title=None):\n",
        "    \"\"\"\n",
        "    Retrieves a worksheet from a Google Sheet specified by its URL. It can\n",
        "    either return a worksheet by its title or by its index.\n",
        "\n",
        "    Parameters:\n",
        "        spread_url (str): The URL of the Google Sheet.\n",
        "        sheet_index (int, optional): The index of the worksheet to retrieve.\n",
        "            Defaults to 0.\n",
        "        sheet_title (str, optional): The title of the worksheet to retrieve.\n",
        "            If specified, this parameter takes precedence over sheet_index.\n",
        "\n",
        "    Returns:\n",
        "        gspread.models.Worksheet: The worksheet object from the Google Sheet.\n",
        "    \"\"\"\n",
        "    if sheet_title:\n",
        "        sheet = gc.open_by_url(spread_url).worksheet(sheet_title)\n",
        "    else:\n",
        "        sheet = gc.open_by_url(spread_url).get_worksheet(sheet_index)\n",
        "    return sheet\n",
        "\n",
        "\n",
        "@retry_on_quota_exceeded()\n",
        "def df_from_spread_url(spread_url, sheet_index=0, sheet_title=None):\n",
        "    \"\"\"\n",
        "    Retrieves data from a specified worksheet in a Google Sheet and converts it\n",
        "    into a pandas DataFrame. It can either retrieve a worksheet by its title or\n",
        "    by its index.\n",
        "\n",
        "    Parameters:\n",
        "        spread_url (str): The URL of the Google Sheet.\n",
        "        sheet_index (int, optional): The index of the worksheet to retrieve.\n",
        "            Defaults to 0.\n",
        "        sheet_title (str, optional): The title of the worksheet to retrieve.\n",
        "            If specified, this parameter takes precedence over sheet_index.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: A DataFrame containing the data from the Google Sheet.\n",
        "    \"\"\"\n",
        "    sheet = open_sheet_from_url(spread_url, sheet_index, sheet_title)\n",
        "    return pd.DataFrame(sheet.get_all_records())\n",
        "\n",
        "\n",
        "@retry_on_quota_exceeded()\n",
        "def df_from_csv_url(url, header_row_idx=None, index_col_idx=None):\n",
        "    \"\"\"\n",
        "    Downloads a CSV file from a given Google Drive URL and converts it into a\n",
        "    pandas DataFrame. The user can specify which row to use as the header and\n",
        "    which column to use as the index.\n",
        "\n",
        "    Parameters:\n",
        "        url (str): The URL of the CSV file on Google Drive.\n",
        "        header_row_idx (int, optional): The row number to use as the header\n",
        "            (0-indexed). Defaults to None.\n",
        "        index_col_idx (int, optional): The column number to use as the index\n",
        "            (0-indexed). Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: A DataFrame containing the data from the CSV file.\n",
        "    \"\"\"\n",
        "    file_id = extract_drive_id(url)\n",
        "    request = drive_service.files().get_media(fileId=file_id)\n",
        "    file_path = f'/tmp/{file_id}.csv'\n",
        "    with open(file_path, 'wb') as f:\n",
        "        downloader = MediaIoBaseDownload(f, request)\n",
        "        done = False\n",
        "        while done is False:\n",
        "            status, done = downloader.next_chunk()\n",
        "    return pd.read_csv(file_path, header=header_row_idx, index_col=index_col_idx)\n",
        "\n",
        "\n",
        "@retry_on_quota_exceeded()\n",
        "def get_cols_by_name_from_sheet(sheet, column_names, header_row=1):\n",
        "    \"\"\"\n",
        "    Retrieves specified columns from a Google Sheet and returns them as a\n",
        "    pandas DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "        sheet (gspread.Sheet): The Google Sheet object.\n",
        "        column_names (list): A list of column names to fetch.\n",
        "        header_row (int): The row number of the header (1-indexed).\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing the columns.\n",
        "        None: If any column is not found.\n",
        "    \"\"\"\n",
        "    # Get the header row\n",
        "    header = sheet.row_values(header_row)\n",
        "\n",
        "    # Find the indices of the columns\n",
        "    col_indices = []\n",
        "    for column_name in column_names:\n",
        "        try:\n",
        "            col_idx = header.index(column_name) + 1\n",
        "            col_indices.append((column_name, col_idx))\n",
        "        except ValueError:\n",
        "            raise ValueError(f\"Column '{column_name}' not found in the sheet.\")\n",
        "\n",
        "    # Get all values in the specified columns, including the header\n",
        "    data = {}\n",
        "    for col_name, col_idx in col_indices:\n",
        "        column_values = sheet.col_values(col_idx)\n",
        "        data[col_name] = column_values[1:]  # Skip the header\n",
        "\n",
        "    # Create a DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "@retry_on_quota_exceeded()\n",
        "def get_files_info_from_folder(folder_url):\n",
        "    \"\"\"\n",
        "    Fetches the details of files contained in a specified Google Drive folder\n",
        "    and returns a list of dictionaries, each containing the file's name, URL,\n",
        "    and MIME type.\n",
        "\n",
        "    Parameters:\n",
        "        folder_url (str): The URL of the Google Drive folder.\n",
        "\n",
        "    Returns:\n",
        "        List[dict]: A list of dictionaries containing file information,\n",
        "                    each with 'name', 'url', and 'type' keys.\n",
        "    \"\"\"\n",
        "    folder_id = extract_drive_id(folder_url)\n",
        "    query = f\"'{folder_id}' in parents and trashed=false\"\n",
        "    results = drive_service.files().list(\n",
        "        q=query,\n",
        "        fields=\"files(id, name, webViewLink, mimeType)\"\n",
        "    ).execute()\n",
        "    items = results.get('files', [])\n",
        "\n",
        "    files_info = []\n",
        "    for item in items:\n",
        "        files_info.append({\n",
        "            'name': item['name'],\n",
        "            'url': item['webViewLink'],\n",
        "            'type': item['mimeType']\n",
        "        })\n",
        "    return files_info\n",
        "\n",
        "\n",
        "@retry_on_quota_exceeded()\n",
        "def move_file(file_url, dst_folder_url):\n",
        "    \"\"\"\n",
        "    Moves a Google Drive file to a specified folder.\n",
        "\n",
        "    Parameters:\n",
        "        file_url (str): The URL of the Google Drive file.\n",
        "        dst_folder_url (str): The URL of the destination Google Drive folder.\n",
        "    \"\"\"\n",
        "    # Extract folder ID from destination folder URL\n",
        "    dst_folder_id = extract_drive_id(dst_folder_url)\n",
        "\n",
        "    # Extract file ID from file URL\n",
        "    file_id = extract_drive_id(file_url)\n",
        "\n",
        "    # Retrieve the current parents to remove them\n",
        "    file = drive_service.files().get(fileId=file_id, fields='parents').execute()\n",
        "    previous_parents = \",\".join(file.get('parents'))\n",
        "\n",
        "    # Move the file to the new folder\n",
        "    drive_service.files().update(\n",
        "        fileId=file_id,\n",
        "        addParents=dst_folder_id,\n",
        "        removeParents=previous_parents,\n",
        "        fields='id, parents'\n",
        "    ).execute()\n",
        "\n",
        "\n",
        "@retry_on_quota_exceeded()\n",
        "def append_df_to_sheet(df, dst_sheet):\n",
        "    \"\"\"\n",
        "    Appends the rows of a pandas DataFrame to a specified Google Sheet\n",
        "    worksheet, ensuring that only columns matching the destination sheet's\n",
        "    columns are included and that the order of columns in the DataFrame matches\n",
        "    the order in the destination sheet.\n",
        "\n",
        "    If the DataFrame does not have all the columns present in the destination\n",
        "    sheet, the missing columns will be added with empty string values.\n",
        "\n",
        "    Parameters:\n",
        "        df (pandas.DataFrame): The DataFrame to append to the Google Sheet.\n",
        "        dst_sheet (gspread.models.Worksheet): The destination Google Sheet.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the column names of the destination sheet\n",
        "    sheet_cols = dst_sheet.row_values(1)\n",
        "    df_cols = list(df.columns)\n",
        "\n",
        "    # Only keep columns in df that exist in the destination sheet\n",
        "    non_dst_cols = [col for col in df_cols if col not in sheet_cols]\n",
        "    df = df.drop(columns=non_dst_cols)\n",
        "\n",
        "    # Reindex df to match the order of columns in the destination sheet\n",
        "    df = df.reindex(columns=sheet_cols)\n",
        "\n",
        "    # Replace null values with an empty string\n",
        "    df = df.fillna('')\n",
        "\n",
        "    # Append rows to the destination sheet\n",
        "    dst_sheet.append_rows(df.values.tolist())\n",
        "\n",
        "\n",
        "@retry_on_quota_exceeded()\n",
        "def create_spread_from_df(df, new_name, dst_folder_url):\n",
        "    \"\"\"\n",
        "    Creates a new Google Sheet in the specified folder with the given name and\n",
        "    populates it with data from the provided DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): The DataFrame to populate the Google Sheet with.\n",
        "        new_name (str): The name of the new Google Sheet.\n",
        "        dst_folder_url (str): The URL of the destination Google Drive folder.\n",
        "    \"\"\"\n",
        "    # Create a new Google Sheet\n",
        "    spreadsheet = gc.create(new_name)\n",
        "    sheet = spreadsheet.get_worksheet(0)\n",
        "\n",
        "    # Extract folder ID from destination folder URL\n",
        "    dst_folder_id = extract_drive_id(dst_folder_url)\n",
        "\n",
        "    # Move the new Google Sheet to the destination folder\n",
        "    file_id = spreadsheet.id\n",
        "    drive_service.files().update(\n",
        "        fileId=file_id,\n",
        "        addParents=dst_folder_id,\n",
        "        fields='id, parents'\n",
        "    ).execute()\n",
        "\n",
        "    # Replace null values with an empty string\n",
        "    df = df.fillna('')\n",
        "\n",
        "    # Populate the new Google Sheet with data from the DataFrame\n",
        "    sheet.update([df.columns.values.tolist()] + df.values.tolist())\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    pass\n",
        "    # data = {\n",
        "    #     'A': [1, pd.NA, 3],\n",
        "    #     'B': [4, 5, 6],\n",
        "    #     'C': [7, 8, 9],\n",
        "    # }\n",
        "    # df = pd.DataFrame(data)\n",
        "    # create_spread_from_df(df, 'New Google Sheet', 'https://drive.google.com/drive/folders/1Ne6IBg1tq_ftv49Hxb1vvBh1tKCVU9MK')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LzVhAhsMwlZ9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}